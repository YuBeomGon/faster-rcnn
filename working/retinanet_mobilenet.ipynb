{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fitting-knitting",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "# from torch.utils.data.sampler import Sampler\n",
    "import torch.optim as optim\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from dataset import LbpDataset, train_transforms, val_transforms, test_transforms, collate_fn, get_data\n",
    "from visualize import visualize\n",
    "# from rcnn_model import fasterrcnn_resnet201_fpn, FastRCNNPredictor\n",
    "from engine import evaluate\n",
    "import utils\n",
    "from train_lbp import get_train_test_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "painful-runner",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.detection.backbone_utils import resnet_fpn_backbone, _validate_trainable_layers\n",
    "from torchvision.ops.feature_pyramid_network import LastLevelP6P7\n",
    "from torchvision.models.detection.retinanet import RetinaNet\n",
    "from torch.hub import load_state_dict_from_url\n",
    "from torchvision.models.detection.backbone_utils import mobilenet_backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "plain-antique",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.detection.retinanet import retinanet_resnet50_fpn\n",
    "from torchvision.models.detection.faster_rcnn import fasterrcnn_mobilenet_v3_large_fpn\n",
    "# model = torchvision.models.detection.fasterrcnn_mobilenet_v3_large_fpn(pretrained=True)\n",
    "# model = retinanet_resnet50_fpn(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "creative-vault",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retinanet_resnet18_fpn(pretrained=False, progress=True,\n",
    "                           num_classes=91, pretrained_backbone=True, trainable_backbone_layers=None, **kwargs):\n",
    "    trainable_backbone_layers = _validate_trainable_layers(\n",
    "        pretrained or pretrained_backbone, trainable_backbone_layers, 5, 3)\n",
    "\n",
    "    if pretrained:\n",
    "        # no need to download the backbone if pretrained is set\n",
    "        pretrained_backbone = False\n",
    "    # skip P2 because it generates too many anchors (according to their paper)\n",
    "    backbone = resnet_fpn_backbone('resnet50', pretrained_backbone, returned_layers=[2, 3, 4],\n",
    "                                   extra_blocks=LastLevelP6P7(256, 256), trainable_layers=trainable_backbone_layers)\n",
    "    model = RetinaNet(backbone, num_classes, **kwargs)\n",
    "#     if pretrained:\n",
    "#         state_dict = load_state_dict_from_url(model_urls['retinanet_resnet50_fpn_coco'],\n",
    "#                                               progress=progress)\n",
    "#         model.load_state_dict(state_dict)\n",
    "#         overwrite_eps(model, 0.0)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "champion-instruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.detection.anchor_utils import AnchorGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dangerous-property",
   "metadata": {},
   "outputs": [],
   "source": [
    "# anchor_sizes = ((32, 64, 128, 256, 512, ), ) * 5\n",
    "# print(anchor_sizes)\n",
    "# aspect_ratios = ((0.5, 0.75, 1.0, 1.5, 2.0),) * len(anchor_sizes)\n",
    "# aspect_ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "severe-planet",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retinanet_mobilenet_fpn(pretrained=False, progress=True,\n",
    "                           num_classes=91, pretrained_backbone=True, trainable_backbone_layers=None, **kwargs):\n",
    "    trainable_backbone_layers = _validate_trainable_layers(\n",
    "        pretrained or pretrained_backbone, trainable_backbone_layers, 5, 3)\n",
    "\n",
    "    if pretrained:\n",
    "        # no need to download the backbone if pretrained is set\n",
    "        pretrained_backbone = False\n",
    "    # skip P2 because it generates too many anchors (according to their paper)\n",
    "#     backbone = resnet_fpn_backbone('resnet50', pretrained_backbone, returned_layers=[2, 3, 4],\n",
    "#                                    extra_blocks=LastLevelP6P7(256, 256), trainable_layers=trainable_backbone_layers)\n",
    "    anchor_sizes = ((32, 64, 128, 256), ) * 3\n",
    "    aspect_ratios = ((0.5, 1.0, 2.0),) * len(anchor_sizes)\n",
    "    rpn_anchor_generator=AnchorGenerator(anchor_sizes, aspect_ratios)\n",
    "    \n",
    "    backbone = mobilenet_backbone(\"mobilenet_v3_small\", pretrained_backbone, True,\n",
    "                                  trainable_layers=trainable_backbone_layers)\n",
    "    \n",
    "#     backbone = mobilenet_backbone(\"mobilenet_v3_large\", pretrained_backbone, True,\n",
    "#                                   trainable_layers=trainable_backbone_layers)    \n",
    "    model = RetinaNet(backbone, num_classes, anchor_generator=rpn_anchor_generator, **kwargs)\n",
    "#     if pretrained:\n",
    "#         state_dict = load_state_dict_from_url(model_urls['retinanet_resnet50_fpn_coco'],\n",
    "#                                               progress=progress)\n",
    "#         model.load_state_dict(state_dict)\n",
    "#         overwrite_eps(model, 0.0)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "patient-revolution",
   "metadata": {},
   "outputs": [],
   "source": [
    "import easydict \n",
    "args = easydict.EasyDict({ \"batch_size\": 16, \n",
    "                          \"epochs\": 120, \n",
    "                          \"data\": 0, \n",
    "                          'lr':0.002,\n",
    "                         'momentum':0.9,\n",
    "                         'weight_decay':1e-4,\n",
    "                         'start_epoch':0,\n",
    "                         'gpu':0,\n",
    "                          'workers':12,\n",
    "                         'print_freq':1000,\n",
    "                         'output_dir':'../trained_model/retinanet/'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "photographic-worker",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "path = Path(args.output_dir.split('checkpoint')[0])\n",
    "path.mkdir(parents=True, exist_ok=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "public-universal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "ngpus_per_node = torch.cuda.device_count()\n",
    "print(ngpus_per_node)\n",
    "GPU_NUM = args.gpu # 원하는 GPU 번호 입력\n",
    "device = torch.device(f'cuda:{GPU_NUM}' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.set_device(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "royal-thumb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>file_name</th>\n",
       "      <th>task</th>\n",
       "      <th>bbox</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>w</th>\n",
       "      <th>h</th>\n",
       "      <th>label</th>\n",
       "      <th>occluded</th>\n",
       "      <th>des</th>\n",
       "      <th>cell_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>patch_images/2021.01.14/LBC424-20210111(1)/LBC...</td>\n",
       "      <td>[AS6] LBC424</td>\n",
       "      <td>[1539, 199, 139, 211]</td>\n",
       "      <td>1539</td>\n",
       "      <td>199</td>\n",
       "      <td>139</td>\n",
       "      <td>211</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ASC-US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>patch_images/2021.01.14/LBC424-20210111(1)/LBC...</td>\n",
       "      <td>[AS6] LBC424</td>\n",
       "      <td>[1337, 102, 256, 136]</td>\n",
       "      <td>1337</td>\n",
       "      <td>102</td>\n",
       "      <td>256</td>\n",
       "      <td>136</td>\n",
       "      <td>AS</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ASC-US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>patch_images/2021.01.14/LBC424-20210111(1)/LBC...</td>\n",
       "      <td>[AS6] LBC424</td>\n",
       "      <td>[220, 619, 166, 169]</td>\n",
       "      <td>220</td>\n",
       "      <td>619</td>\n",
       "      <td>166</td>\n",
       "      <td>169</td>\n",
       "      <td>AS</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ASC-US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>patch_images/2021.01.14/LBC424-20210111(1)/LBC...</td>\n",
       "      <td>[AS6] LBC424</td>\n",
       "      <td>[658, 1747, 191, 166]</td>\n",
       "      <td>658</td>\n",
       "      <td>1747</td>\n",
       "      <td>191</td>\n",
       "      <td>166</td>\n",
       "      <td>AS</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ASC-US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>patch_images/2021.01.14/LBC424-20210111(1)/LBC...</td>\n",
       "      <td>[AS6] LBC424</td>\n",
       "      <td>[1571, 365, 136, 146]</td>\n",
       "      <td>1571</td>\n",
       "      <td>365</td>\n",
       "      <td>136</td>\n",
       "      <td>146</td>\n",
       "      <td>AS</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ASC-US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                          file_name          task  \\\n",
       "0   0  patch_images/2021.01.14/LBC424-20210111(1)/LBC...  [AS6] LBC424   \n",
       "1   1  patch_images/2021.01.14/LBC424-20210111(1)/LBC...  [AS6] LBC424   \n",
       "2   2  patch_images/2021.01.14/LBC424-20210111(1)/LBC...  [AS6] LBC424   \n",
       "3   3  patch_images/2021.01.14/LBC424-20210111(1)/LBC...  [AS6] LBC424   \n",
       "4   4  patch_images/2021.01.14/LBC424-20210111(1)/LBC...  [AS6] LBC424   \n",
       "\n",
       "                    bbox  xmin  ymin    w    h label  occluded  des cell_type  \n",
       "0  [1539, 199, 139, 211]  1539   199  139  211     C         0  NaN    ASC-US  \n",
       "1  [1337, 102, 256, 136]  1337   102  256  136    AS         0  NaN    ASC-US  \n",
       "2   [220, 619, 166, 169]   220   619  166  169    AS         0  NaN    ASC-US  \n",
       "3  [658, 1747, 191, 166]   658  1747  191  166    AS         0  NaN    ASC-US  \n",
       "4  [1571, 365, 136, 146]  1571   365  136  146    AS         0  NaN    ASC-US  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../data/df.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "wooden-lender",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['C', 'AS', 'ASC-US', 'LSIL', 'LS', 'HS', 'Negative', 'Carcinoma',\n",
       "       'ASC-H', 'ASC-US with HPV infection', 'HSIL with HPV infection',\n",
       "       'Candida', 'HSIL', 'AH', 'ASCUS-SIL', '판독불가',\n",
       "       'LSIL with HPV infection', 'H', 'Benign atypia'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "digital-holly",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>file_name</th>\n",
       "      <th>task</th>\n",
       "      <th>bbox</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>w</th>\n",
       "      <th>h</th>\n",
       "      <th>label</th>\n",
       "      <th>occluded</th>\n",
       "      <th>des</th>\n",
       "      <th>cell_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>patch_images/2021.01.14/LBC424-20210111(1)/LBC...</td>\n",
       "      <td>[AS6] LBC424</td>\n",
       "      <td>[1539, 199, 139, 211]</td>\n",
       "      <td>1539</td>\n",
       "      <td>199</td>\n",
       "      <td>139</td>\n",
       "      <td>211</td>\n",
       "      <td>Carcinoma</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ASC-US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>patch_images/2021.01.14/LBC424-20210111(1)/LBC...</td>\n",
       "      <td>[AS6] LBC424</td>\n",
       "      <td>[1337, 102, 256, 136]</td>\n",
       "      <td>1337</td>\n",
       "      <td>102</td>\n",
       "      <td>256</td>\n",
       "      <td>136</td>\n",
       "      <td>ASC-US</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ASC-US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>patch_images/2021.01.14/LBC424-20210111(1)/LBC...</td>\n",
       "      <td>[AS6] LBC424</td>\n",
       "      <td>[220, 619, 166, 169]</td>\n",
       "      <td>220</td>\n",
       "      <td>619</td>\n",
       "      <td>166</td>\n",
       "      <td>169</td>\n",
       "      <td>ASC-US</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ASC-US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>patch_images/2021.01.14/LBC424-20210111(1)/LBC...</td>\n",
       "      <td>[AS6] LBC424</td>\n",
       "      <td>[658, 1747, 191, 166]</td>\n",
       "      <td>658</td>\n",
       "      <td>1747</td>\n",
       "      <td>191</td>\n",
       "      <td>166</td>\n",
       "      <td>ASC-US</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ASC-US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>patch_images/2021.01.14/LBC424-20210111(1)/LBC...</td>\n",
       "      <td>[AS6] LBC424</td>\n",
       "      <td>[1571, 365, 136, 146]</td>\n",
       "      <td>1571</td>\n",
       "      <td>365</td>\n",
       "      <td>136</td>\n",
       "      <td>146</td>\n",
       "      <td>ASC-US</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ASC-US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                          file_name          task  \\\n",
       "0   0  patch_images/2021.01.14/LBC424-20210111(1)/LBC...  [AS6] LBC424   \n",
       "1   1  patch_images/2021.01.14/LBC424-20210111(1)/LBC...  [AS6] LBC424   \n",
       "2   2  patch_images/2021.01.14/LBC424-20210111(1)/LBC...  [AS6] LBC424   \n",
       "3   3  patch_images/2021.01.14/LBC424-20210111(1)/LBC...  [AS6] LBC424   \n",
       "4   4  patch_images/2021.01.14/LBC424-20210111(1)/LBC...  [AS6] LBC424   \n",
       "\n",
       "                    bbox  xmin  ymin    w    h      label  occluded  des  \\\n",
       "0  [1539, 199, 139, 211]  1539   199  139  211  Carcinoma         0  NaN   \n",
       "1  [1337, 102, 256, 136]  1337   102  256  136     ASC-US         0  NaN   \n",
       "2   [220, 619, 166, 169]   220   619  166  169     ASC-US         0  NaN   \n",
       "3  [658, 1747, 191, 166]   658  1747  191  166     ASC-US         0  NaN   \n",
       "4  [1571, 365, 136, 146]  1571   365  136  146     ASC-US         0  NaN   \n",
       "\n",
       "  cell_type  \n",
       "0    ASC-US  \n",
       "1    ASC-US  \n",
       "2    ASC-US  \n",
       "3    ASC-US  \n",
       "4    ASC-US  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataset_util import CLASS_MAPPER\n",
    "df.label = df.label.apply(lambda x : CLASS_MAPPER[str(x)])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "stylish-cliff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['label_id'] = df.label.apply(lambda x : 0. if 'Benign' in x or 'Negative' in x else 1.)\n",
    "# df.label_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "mature-hamburg",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 7524 train 5643 test 1881\n",
      "5643\n",
      "1881\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../../data/df.csv')\n",
    "df.head()\n",
    "# Data loading code#\n",
    "data_dir = '../../data/df.csv'\n",
    "train_list, test_list = get_train_test_list(data_dir)\n",
    "train_dataset = LbpDataset(train_list, default_path='/home/Dataset/scl/', transform=train_transforms)\n",
    "test_dataset = LbpDataset(test_list, default_path='/home/Dataset/scl/', transform=val_transforms)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "acoustic-studio",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9735, 12)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "useful-bulgaria",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = torch.utils.data.RandomSampler(train_dataset)\n",
    "test_sampler = torch.utils.data.SequentialSampler(test_dataset)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=args.batch_size,\n",
    "    sampler=train_sampler, num_workers=args.workers,\n",
    "    collate_fn=utils.collate_fn)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=args.batch_size,\n",
    "    sampler=test_sampler, num_workers=args.workers,\n",
    "    collate_fn=utils.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "invisible-curve",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model is loaded to gpu\n"
     ]
    }
   ],
   "source": [
    "num_classes = 2\n",
    "model = retinanet_mobilenet_fpn(pretrained=False, min_size=800, max_size=800, num_classes=2)\n",
    "# model = retinanet_resnet50_fpn(pretrained=False, min_size=1024, max_size=1024, num_classes=2)\n",
    "# model = retinanet_resnet18_fpn(pretrained=False, min_size=1024, max_size=1024, num_classes=2)\n",
    "\n",
    "device = torch.device('cuda')\n",
    "model.to(device)\n",
    "print('model is loaded to gpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "primary-perth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = retinanet_mobilenet_fpn(pretrained=False, min_size=1024, max_size=1024, num_classes=2)\n",
    "# torch.save(model.state_dict(), 'ret1.pt')\n",
    "\n",
    "# model = retinanet_resnet18_fpn(pretrained=False, min_size=1024, max_size=1024, num_classes=2)\n",
    "# torch.save(model.state_dict(), 'ret2.pt')\n",
    "\n",
    "# model = retinanet_resnet50_fpn(pretrained=False, min_size=1024, max_size=1024, num_classes=2)\n",
    "# torch.save(model.state_dict(), 'ret3.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "horizontal-contributor",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.Adam(params, lr=args.lr, weight_decay=args.weight_decay)\n",
    "# optimizer = torch.optim.SGD(\n",
    "#        params, lr=args.lr, momentum=args.momentum, weight_decay=args.weight_decay)\n",
    "lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[20, 40, 60, 80, 100], \n",
    "                                                    gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "broad-lawyer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate(model, test_loader, device=device)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "color-interpretation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0]  [  0/353]  eta: 0:31:07  lr: 0.002000  loss: 3.8123 (3.8123)  classification: 1.1369 (1.1369)  bbox_regression: 2.6754 (2.6754)  time: 5.2903  data: 4.9132  max mem: 1876\n",
      "Epoch: [0]  [352/353]  eta: 0:00:00  lr: 0.002000  loss: 2.3755 (239092.4548)  classification: 0.8934 (239090.2487)  bbox_regression: 1.4975 (2.2123)  time: 0.2883  data: 0.1270  max mem: 1964\n",
      "Epoch: [0] Total time: 0:02:07 (0.3612 s / it)\n",
      "Epoch: [1]  [  0/353]  eta: 0:28:12  lr: 0.002000  loss: 2.1778 (2.1778)  classification: 0.8393 (0.8393)  bbox_regression: 1.3384 (1.3384)  time: 4.7935  data: 4.5900  max mem: 1964\n",
      "Epoch: [1]  [352/353]  eta: 0:00:00  lr: 0.002000  loss: 3.5104 (583.6978)  classification: 0.8425 (0.8343)  bbox_regression: 2.6661 (582.8634)  time: 0.2779  data: 0.1182  max mem: 1964\n",
      "Epoch: [1] Total time: 0:02:09 (0.3665 s / it)\n",
      "Epoch: [2]  [  0/353]  eta: 0:30:30  lr: 0.002000  loss: 3.1999 (3.1999)  classification: 0.8493 (0.8493)  bbox_regression: 2.3506 (2.3506)  time: 5.1861  data: 4.9424  max mem: 1964\n",
      "Epoch: [2]  [352/353]  eta: 0:00:00  lr: 0.002000  loss: 1.3794 (2.4685)  classification: 0.8102 (0.8278)  bbox_regression: 0.5882 (1.6407)  time: 0.2397  data: 0.0823  max mem: 1964\n",
      "Epoch: [2] Total time: 0:02:08 (0.3646 s / it)\n",
      "Epoch: [3]  [  0/353]  eta: 0:30:07  lr: 0.002000  loss: 1.4529 (1.4529)  classification: 0.8767 (0.8767)  bbox_regression: 0.5763 (0.5763)  time: 5.1199  data: 4.9124  max mem: 1964\n",
      "Epoch: [3]  [352/353]  eta: 0:00:00  lr: 0.002000  loss: 1.4594 (1.4554)  classification: 0.8299 (0.8276)  bbox_regression: 0.6295 (0.6278)  time: 0.2642  data: 0.1074  max mem: 1964\n",
      "Epoch: [3] Total time: 0:02:08 (0.3647 s / it)\n",
      "Epoch: [4]  [  0/353]  eta: 0:28:13  lr: 0.002000  loss: 1.5468 (1.5468)  classification: 0.8707 (0.8707)  bbox_regression: 0.6761 (0.6761)  time: 4.7976  data: 4.5920  max mem: 1964\n",
      "Epoch: [4]  [352/353]  eta: 0:00:00  lr: 0.002000  loss: 1.4342 (1.6639)  classification: 0.8124 (0.8280)  bbox_regression: 0.6145 (0.8360)  time: 0.2457  data: 0.0941  max mem: 1964\n",
      "Epoch: [4] Total time: 0:02:08 (0.3628 s / it)\n",
      "Epoch: [5]  [  0/353]  eta: 0:28:56  lr: 0.002000  loss: 1.2902 (1.2902)  classification: 0.7777 (0.7777)  bbox_regression: 0.5124 (0.5124)  time: 4.9182  data: 4.7371  max mem: 1964\n",
      "Epoch: [5]  [352/353]  eta: 0:00:00  lr: 0.002000  loss: 1.8164 (1483850.0146)  classification: 0.9923 (834318.5064)  bbox_regression: 0.8296 (649531.5115)  time: 0.2753  data: 0.1164  max mem: 1964\n",
      "Epoch: [5] Total time: 0:02:08 (0.3629 s / it)\n",
      "Epoch: [6]  [  0/353]  eta: 0:28:01  lr: 0.002000  loss: 1.7921 (1.7921)  classification: 1.0118 (1.0118)  bbox_regression: 0.7803 (0.7803)  time: 4.7637  data: 4.5772  max mem: 1964\n",
      "Epoch: [6]  [352/353]  eta: 0:00:00  lr: 0.002000  loss: 1.6009 (3901.7233)  classification: 0.9055 (3828.6939)  bbox_regression: 0.6734 (73.0294)  time: 0.2540  data: 0.0914  max mem: 1964\n",
      "Epoch: [6] Total time: 0:02:11 (0.3713 s / it)\n",
      "Epoch: [7]  [  0/353]  eta: 0:38:17  lr: 0.002000  loss: 1.4791 (1.4791)  classification: 0.7926 (0.7926)  bbox_regression: 0.6864 (0.6864)  time: 6.5093  data: 6.2539  max mem: 1964\n",
      "Epoch: [7]  [352/353]  eta: 0:00:00  lr: 0.002000  loss: 1.5111 (1.5150)  classification: 0.8665 (0.8788)  bbox_regression: 0.6242 (0.6361)  time: 0.2768  data: 0.1071  max mem: 1964\n",
      "Epoch: [7] Total time: 0:02:16 (0.3855 s / it)\n",
      "Epoch: [8]  [  0/353]  eta: 0:29:26  lr: 0.002000  loss: 1.4633 (1.4633)  classification: 0.8721 (0.8721)  bbox_regression: 0.5911 (0.5911)  time: 5.0032  data: 4.7476  max mem: 1964\n",
      "Epoch: [8]  [352/353]  eta: 0:00:00  lr: 0.002000  loss: 1.4612 (1.4897)  classification: 0.8357 (0.8581)  bbox_regression: 0.6236 (0.6316)  time: 0.2582  data: 0.1016  max mem: 1964\n",
      "Epoch: [8] Total time: 0:02:13 (0.3787 s / it)\n",
      "Epoch: [9]  [  0/353]  eta: 0:27:59  lr: 0.002000  loss: 1.3646 (1.3646)  classification: 0.7723 (0.7723)  bbox_regression: 0.5923 (0.5923)  time: 4.7574  data: 4.5197  max mem: 1964\n",
      "Epoch: [9]  [352/353]  eta: 0:00:00  lr: 0.002000  loss: 1.5580 (456583.5095)  classification: 0.9327 (456582.8799)  bbox_regression: 0.6299 (0.6315)  time: 0.2635  data: 0.1095  max mem: 1964\n",
      "Epoch: [9] Total time: 0:02:10 (0.3707 s / it)\n",
      "Epoch: [10]  [  0/353]  eta: 0:29:33  lr: 0.002000  loss: 1.4965 (1.4965)  classification: 0.9709 (0.9709)  bbox_regression: 0.5257 (0.5257)  time: 5.0233  data: 4.8349  max mem: 1964\n",
      "Epoch: [10]  [352/353]  eta: 0:00:00  lr: 0.002000  loss: 1.4623 (1.5163)  classification: 0.8429 (0.8856)  bbox_regression: 0.6120 (0.6307)  time: 0.2560  data: 0.0964  max mem: 1964\n",
      "Epoch: [10] Total time: 0:02:11 (0.3714 s / it)\n",
      "Epoch: [11]  [  0/353]  eta: 0:28:33  lr: 0.002000  loss: 1.5869 (1.5869)  classification: 0.8960 (0.8960)  bbox_regression: 0.6910 (0.6910)  time: 4.8542  data: 4.6447  max mem: 1964\n",
      "Epoch: [11]  [352/353]  eta: 0:00:00  lr: 0.002000  loss: 1.4641 (31554.6584)  classification: 0.8270 (0.8500)  bbox_regression: 0.6532 (31553.8081)  time: 0.2659  data: 0.1046  max mem: 1964\n",
      "Epoch: [11] Total time: 0:02:08 (0.3642 s / it)\n",
      "Epoch: [12]  [  0/353]  eta: 0:29:35  lr: 0.002000  loss: 1.0709 (1.0709)  classification: 0.6629 (0.6629)  bbox_regression: 0.4081 (0.4081)  time: 5.0296  data: 4.8251  max mem: 1964\n",
      "Epoch: [12]  [352/353]  eta: 0:00:00  lr: 0.002000  loss: 1.4483 (1.5944)  classification: 0.8536 (0.9537)  bbox_regression: 0.6050 (0.6407)  time: 0.2771  data: 0.1094  max mem: 1964\n",
      "Epoch: [12] Total time: 0:02:11 (0.3732 s / it)\n",
      "Epoch: [13]  [  0/353]  eta: 0:27:48  lr: 0.002000  loss: 1.4469 (1.4469)  classification: 0.8539 (0.8539)  bbox_regression: 0.5929 (0.5929)  time: 4.7268  data: 4.5170  max mem: 1964\n",
      "Epoch: [13]  [352/353]  eta: 0:00:00  lr: 0.002000  loss: 1.4514 (1.4931)  classification: 0.8289 (0.8330)  bbox_regression: 0.5998 (0.6600)  time: 0.2643  data: 0.0972  max mem: 1964\n",
      "Epoch: [13] Total time: 0:02:14 (0.3819 s / it)\n",
      "Epoch: [14]  [  0/353]  eta: 0:28:49  lr: 0.002000  loss: 1.3399 (1.3399)  classification: 0.7864 (0.7864)  bbox_regression: 0.5535 (0.5535)  time: 4.9001  data: 4.6603  max mem: 1964\n",
      "Epoch: [14]  [352/353]  eta: 0:00:00  lr: 0.002000  loss: 1.4346 (855761.1210)  classification: 0.8257 (45349.8790)  bbox_regression: 0.6166 (810411.2477)  time: 0.2209  data: 0.0631  max mem: 1964\n",
      "Epoch: [14] Total time: 0:02:12 (0.3767 s / it)\n",
      "Epoch: [15]  [  0/353]  eta: 0:32:05  lr: 0.002000  loss: 1.5913 (1.5913)  classification: 0.8606 (0.8606)  bbox_regression: 0.7307 (0.7307)  time: 5.4540  data: 5.2644  max mem: 1964\n",
      "Epoch: [15]  [352/353]  eta: 0:00:00  lr: 0.002000  loss: 1.9969 (17120213.3043)  classification: 1.1124 (2886077.3708)  bbox_regression: 0.8635 (14234136.0323)  time: 0.2537  data: 0.0884  max mem: 1964\n",
      "Epoch: [15] Total time: 0:02:13 (0.3784 s / it)\n",
      "Epoch: [16]  [  0/353]  eta: 0:32:00  lr: 0.002000  loss: 1.7547 (1.7547)  classification: 1.0697 (1.0697)  bbox_regression: 0.6850 (0.6850)  time: 5.4409  data: 5.2399  max mem: 1964\n",
      "Epoch: [16]  [352/353]  eta: 0:00:00  lr: 0.002000  loss: 1.6112 (16775.9732)  classification: 0.9133 (1.0141)  bbox_regression: 0.6991 (16774.9589)  time: 0.2624  data: 0.0990  max mem: 1964\n",
      "Epoch: [16] Total time: 0:02:13 (0.3770 s / it)\n",
      "Epoch: [17]  [  0/353]  eta: 0:30:26  lr: 0.002000  loss: 1.6022 (1.6022)  classification: 0.8703 (0.8703)  bbox_regression: 0.7319 (0.7319)  time: 5.1750  data: 4.9535  max mem: 1964\n",
      "Epoch: [17]  [352/353]  eta: 0:00:00  lr: 0.002000  loss: 8.3120 (10253299436.6423)  classification: 7.6899 (10253274148.4723)  bbox_regression: 0.6443 (25288.0264)  time: 0.2720  data: 0.1122  max mem: 1964\n",
      "Epoch: [17] Total time: 0:02:11 (0.3716 s / it)\n",
      "Epoch: [18]  [  0/353]  eta: 0:29:51  lr: 0.002000  loss: 6.0894 (6.0894)  classification: 5.4010 (5.4010)  bbox_regression: 0.6885 (0.6885)  time: 5.0745  data: 4.8784  max mem: 1964\n",
      "Epoch: [18]  [352/353]  eta: 0:00:00  lr: 0.002000  loss: 2.1042 (3.6952)  classification: 1.4744 (3.0629)  bbox_regression: 0.6220 (0.6323)  time: 0.2575  data: 0.1056  max mem: 1964\n",
      "Epoch: [18] Total time: 0:02:11 (0.3717 s / it)\n",
      "Epoch: [19]  [  0/353]  eta: 0:27:35  lr: 0.002000  loss: 1.9881 (1.9881)  classification: 1.4931 (1.4931)  bbox_regression: 0.4951 (0.4951)  time: 4.6892  data: 4.4662  max mem: 1964\n",
      "Epoch: [19]  [352/353]  eta: 0:00:00  lr: 0.002000  loss: 1.6715 (28939.5472)  classification: 0.9882 (28656.9634)  bbox_regression: 0.6355 (282.5827)  time: 0.2437  data: 0.0889  max mem: 1964\n",
      "Epoch: [19] Total time: 0:02:10 (0.3692 s / it)\n",
      "Epoch: [20]  [  0/353]  eta: 0:29:56  lr: 0.001000  loss: 3.7465 (3.7465)  classification: 3.0568 (3.0568)  bbox_regression: 0.6897 (0.6897)  time: 5.0879  data: 4.8916  max mem: 1964\n",
      "Epoch: [20]  [352/353]  eta: 0:00:00  lr: 0.001000  loss: 1.5223 (12.8269)  classification: 0.9002 (1.0708)  bbox_regression: 0.6133 (11.7561)  time: 0.2488  data: 0.0941  max mem: 1964\n",
      "Epoch: [20] Total time: 0:02:11 (0.3733 s / it)\n",
      "Epoch: [21]  [  0/353]  eta: 0:31:58  lr: 0.001000  loss: 1.9059 (1.9059)  classification: 1.3294 (1.3294)  bbox_regression: 0.5765 (0.5765)  time: 5.4353  data: 5.2545  max mem: 1964\n",
      "Epoch: [21]  [352/353]  eta: 0:00:00  lr: 0.001000  loss: 1.4606 (1.6085)  classification: 0.8665 (0.9826)  bbox_regression: 0.5955 (0.6260)  time: 0.2708  data: 0.1129  max mem: 1964\n",
      "Epoch: [21] Total time: 0:02:12 (0.3754 s / it)\n",
      "Epoch: [22]  [  0/353]  eta: 0:30:27  lr: 0.001000  loss: 1.4929 (1.4929)  classification: 0.8406 (0.8406)  bbox_regression: 0.6523 (0.6523)  time: 5.1784  data: 4.9925  max mem: 1964\n",
      "Epoch: [22]  [352/353]  eta: 0:00:00  lr: 0.001000  loss: 1.5207 (13185.6939)  classification: 0.8526 (0.9591)  bbox_regression: 0.6303 (13184.7347)  time: 0.2665  data: 0.1068  max mem: 1964\n",
      "Epoch: [22] Total time: 0:02:11 (0.3720 s / it)\n",
      "Epoch: [23]  [  0/353]  eta: 0:28:32  lr: 0.001000  loss: 1.4601 (1.4601)  classification: 0.8783 (0.8783)  bbox_regression: 0.5818 (0.5818)  time: 4.8515  data: 4.6226  max mem: 1964\n",
      "Epoch: [23]  [352/353]  eta: 0:00:00  lr: 0.001000  loss: 7.8567 (839319277.2461)  classification: 7.2661 (839319188.1488)  bbox_regression: 0.5997 (89.1026)  time: 0.2302  data: 0.0690  max mem: 1964\n",
      "Epoch: [23] Total time: 0:02:12 (0.3766 s / it)\n",
      "Epoch: [24]  [  0/353]  eta: 0:27:11  lr: 0.001000  loss: 8.6835 (8.6835)  classification: 8.0884 (8.0884)  bbox_regression: 0.5951 (0.5951)  time: 4.6224  data: 4.4241  max mem: 1964\n",
      "Epoch: [24]  [352/353]  eta: 0:00:00  lr: 0.001000  loss: 4.0358 (5.6112)  classification: 3.4297 (4.9858)  bbox_regression: 0.6529 (0.6254)  time: 0.2684  data: 0.1053  max mem: 1964\n",
      "Epoch: [24] Total time: 0:02:11 (0.3724 s / it)\n",
      "Epoch: [25]  [  0/353]  eta: 0:28:36  lr: 0.001000  loss: 4.0707 (4.0707)  classification: 3.4433 (3.4433)  bbox_regression: 0.6274 (0.6274)  time: 4.8631  data: 4.6682  max mem: 1964\n",
      "Epoch: [25]  [352/353]  eta: 0:00:00  lr: 0.001000  loss: 2.6588 (3.3534)  classification: 2.0184 (2.7304)  bbox_regression: 0.6045 (0.6230)  time: 0.2875  data: 0.1258  max mem: 1964\n",
      "Epoch: [25] Total time: 0:02:10 (0.3685 s / it)\n",
      "Epoch: [26]  [  0/353]  eta: 0:28:30  lr: 0.001000  loss: 2.9985 (2.9985)  classification: 2.3817 (2.3817)  bbox_regression: 0.6168 (0.6168)  time: 4.8459  data: 4.6554  max mem: 1964\n",
      "Epoch: [26]  [352/353]  eta: 0:00:00  lr: 0.001000  loss: 2.2735 (3.5132)  classification: 1.6548 (1.7867)  bbox_regression: 0.6359 (1.7266)  time: 0.2682  data: 0.1071  max mem: 1964\n",
      "Epoch: [26] Total time: 0:02:12 (0.3753 s / it)\n",
      "Epoch: [27]  [  0/353]  eta: 0:29:27  lr: 0.001000  loss: 1.8845 (1.8845)  classification: 1.2012 (1.2012)  bbox_regression: 0.6833 (0.6833)  time: 5.0085  data: 4.7816  max mem: 1964\n",
      "Epoch: [27]  [352/353]  eta: 0:00:00  lr: 0.001000  loss: 3.3809 (135437.0059)  classification: 2.7992 (135436.3852)  bbox_regression: 0.6015 (0.6228)  time: 0.2771  data: 0.1161  max mem: 1964\n",
      "Epoch: [27] Total time: 0:02:12 (0.3744 s / it)\n",
      "Epoch: [28]  [  0/353]  eta: 0:30:29  lr: 0.001000  loss: 3.2648 (3.2648)  classification: 2.6320 (2.6320)  bbox_regression: 0.6328 (0.6328)  time: 5.1821  data: 4.9936  max mem: 1964\n",
      "Epoch: [28]  [352/353]  eta: 0:00:00  lr: 0.001000  loss: 4.4009 (6518.0676)  classification: 3.8092 (6517.4446)  bbox_regression: 0.6148 (0.6231)  time: 0.2639  data: 0.1030  max mem: 1964\n",
      "Epoch: [28] Total time: 0:02:11 (0.3711 s / it)\n",
      "Epoch: [29]  [  0/353]  eta: 0:31:07  lr: 0.001000  loss: 4.0059 (4.0059)  classification: 3.4079 (3.4079)  bbox_regression: 0.5981 (0.5981)  time: 5.2899  data: 5.0729  max mem: 1964\n",
      "Epoch: [29]  [352/353]  eta: 0:00:00  lr: 0.001000  loss: 3.9413 (4.2061)  classification: 3.3746 (3.5741)  bbox_regression: 0.6389 (0.6320)  time: 0.2512  data: 0.0922  max mem: 1964\n",
      "Epoch: [29] Total time: 0:02:11 (0.3733 s / it)\n",
      "Epoch: [30]  [  0/353]  eta: 0:29:56  lr: 0.001000  loss: 4.0411 (4.0411)  classification: 3.4905 (3.4905)  bbox_regression: 0.5506 (0.5506)  time: 5.0886  data: 4.8969  max mem: 1964\n",
      "Epoch: [30]  [352/353]  eta: 0:00:00  lr: 0.001000  loss: 3.4648 (3.7294)  classification: 2.8738 (3.1085)  bbox_regression: 0.5938 (0.6209)  time: 0.2135  data: 0.0558  max mem: 1964\n",
      "Epoch: [30] Total time: 0:02:12 (0.3749 s / it)\n",
      "Epoch: [31]  [  0/353]  eta: 0:29:42  lr: 0.001000  loss: 3.4430 (3.4430)  classification: 2.8615 (2.8615)  bbox_regression: 0.5815 (0.5815)  time: 5.0507  data: 4.8248  max mem: 1964\n",
      "Epoch: [31]  [352/353]  eta: 0:00:00  lr: 0.001000  loss: 3.0510 (4410.3002)  classification: 2.4364 (2.4397)  bbox_regression: 0.6076 (4407.8604)  time: 0.2452  data: 0.0853  max mem: 1964\n",
      "Epoch: [31] Total time: 0:02:11 (0.3713 s / it)\n",
      "Epoch: [32]  [  0/353]  eta: 0:28:14  lr: 0.001000  loss: 2.5695 (2.5695)  classification: 2.0280 (2.0280)  bbox_regression: 0.5415 (0.5415)  time: 4.7992  data: 4.5635  max mem: 1964\n",
      "Epoch: [32]  [352/353]  eta: 0:00:00  lr: 0.001000  loss: 2.5519 (2859.3928)  classification: 1.9496 (2.0727)  bbox_regression: 0.6158 (2857.3201)  time: 0.3067  data: 0.1427  max mem: 1964\n",
      "Epoch: [32] Total time: 0:02:08 (0.3633 s / it)\n",
      "Epoch: [33]  [  0/353]  eta: 0:30:06  lr: 0.001000  loss: 2.1939 (2.1939)  classification: 1.5439 (1.5439)  bbox_regression: 0.6500 (0.6500)  time: 5.1176  data: 4.9260  max mem: 1964\n",
      "Epoch: [33]  [352/353]  eta: 0:00:00  lr: 0.001000  loss: 1.8585 (151112.7846)  classification: 1.2764 (151112.1557)  bbox_regression: 0.6228 (0.6310)  time: 0.2411  data: 0.0805  max mem: 1964\n",
      "Epoch: [33] Total time: 0:02:09 (0.3670 s / it)\n",
      "Epoch: [34]  [  0/353]  eta: 0:27:58  lr: 0.001000  loss: 1.8259 (1.8259)  classification: 1.3119 (1.3119)  bbox_regression: 0.5140 (0.5140)  time: 4.7563  data: 4.5164  max mem: 1964\n",
      "Epoch: [34]  [352/353]  eta: 0:00:00  lr: 0.001000  loss: 1.9647 (22.2435)  classification: 1.2871 (1.3460)  bbox_regression: 0.6071 (20.8975)  time: 0.2445  data: 0.0903  max mem: 1964\n",
      "Epoch: [34] Total time: 0:02:09 (0.3680 s / it)\n",
      "Epoch: [35]  [  0/353]  eta: 0:28:07  lr: 0.001000  loss: 2.2033 (2.2033)  classification: 1.5071 (1.5071)  bbox_regression: 0.6962 (0.6962)  time: 4.7811  data: 4.5601  max mem: 1964\n",
      "Epoch: [35]  [352/353]  eta: 0:00:00  lr: 0.001000  loss: 1.8218 (393.1289)  classification: 1.0547 (1.2878)  bbox_regression: 0.6655 (391.8411)  time: 0.2656  data: 0.1102  max mem: 1964\n",
      "Epoch: [35] Total time: 0:02:09 (0.3669 s / it)\n",
      "Epoch: [36]  [  0/353]  eta: 0:27:38  lr: 0.001000  loss: 1.8029 (1.8029)  classification: 1.1507 (1.1507)  bbox_regression: 0.6522 (0.6522)  time: 4.6976  data: 4.4870  max mem: 1964\n",
      "Epoch: [36]  [352/353]  eta: 0:00:00  lr: 0.001000  loss: 1.7126 (1.8192)  classification: 1.1201 (1.1901)  bbox_regression: 0.6109 (0.6291)  time: 0.2613  data: 0.1035  max mem: 1964\n",
      "Epoch: [36] Total time: 0:02:08 (0.3634 s / it)\n",
      "Epoch: [37]  [  0/353]  eta: 0:28:50  lr: 0.001000  loss: 2.1533 (2.1533)  classification: 1.4315 (1.4315)  bbox_regression: 0.7218 (0.7218)  time: 4.9022  data: 4.7118  max mem: 1964\n",
      "Epoch: [37]  [352/353]  eta: 0:00:00  lr: 0.001000  loss: 1.6149 (30.9078)  classification: 0.9901 (1.1095)  bbox_regression: 0.6006 (29.7983)  time: 0.2458  data: 0.0874  max mem: 1964\n",
      "Epoch: [37] Total time: 0:02:13 (0.3769 s / it)\n",
      "Epoch: [38]  [  0/353]  eta: 0:29:07  lr: 0.001000  loss: 1.4768 (1.4768)  classification: 0.8856 (0.8856)  bbox_regression: 0.5912 (0.5912)  time: 4.9511  data: 4.7462  max mem: 1964\n",
      "Epoch: [38]  [352/353]  eta: 0:00:00  lr: 0.001000  loss: 186254213120.0000 (462959508400.5705)  classification: 169871966208.0000 (443292241740.3750)  bbox_regression: 2593558528.0000 (19667270844.2783)  time: 0.2537  data: 0.0944  max mem: 1964\n",
      "Epoch: [38] Total time: 0:02:11 (0.3732 s / it)\n",
      "Epoch: [39]  [  0/353]  eta: 0:30:42  lr: 0.001000  loss: 53860495360.0000 (53860495360.0000)  classification: 53328891904.0000 (53328891904.0000)  bbox_regression: 531603968.0000 (531603968.0000)  time: 5.2196  data: 4.9935  max mem: 1964\n",
      "Epoch: [39]  [352/353]  eta: 0:00:00  lr: 0.001000  loss: 7363845632.0000 (263100316648.5212)  classification: 7363845632.0000 (263098403955.1161)  bbox_regression: 1.4685 (1912795.4582)  time: 0.2359  data: 0.0825  max mem: 1964\n",
      "Epoch: [39] Total time: 0:02:13 (0.3794 s / it)\n",
      "Epoch: [40]  [  0/353]  eta: 0:29:24  lr: 0.000500  loss: 4353102336.0000 (4353102336.0000)  classification: 4353102336.0000 (4353102336.0000)  bbox_regression: 2.2660 (2.2660)  time: 4.9985  data: 4.7890  max mem: 1964\n",
      "Epoch: [40]  [352/353]  eta: 0:00:00  lr: 0.000500  loss: 1342018560.0000 (3129756585.4278)  classification: 1342018560.0000 (3129756585.4278)  bbox_regression: 1.3926 (1.5536)  time: 0.2493  data: 0.0945  max mem: 1964\n",
      "Epoch: [40] Total time: 0:02:10 (0.3690 s / it)\n",
      "Epoch: [41]  [  0/353]  eta: 0:30:05  lr: 0.000500  loss: 1105745664.0000 (1105745664.0000)  classification: 1105745664.0000 (1105745664.0000)  bbox_regression: 1.7149 (1.7149)  time: 5.1153  data: 4.9109  max mem: 1964\n",
      "Epoch: [41]  [352/353]  eta: 0:00:00  lr: 0.000500  loss: 419022496.0000 (498026480.8159)  classification: 419022496.0000 (498026480.8159)  bbox_regression: 1.6002 (1.5446)  time: 0.2791  data: 0.1136  max mem: 1964\n",
      "Epoch: [41] Total time: 0:02:16 (0.3858 s / it)\n",
      "Epoch: [42]  [  0/353]  eta: 0:30:36  lr: 0.000500  loss: 340369760.0000 (340369760.0000)  classification: 340369760.0000 (340369760.0000)  bbox_regression: 1.6532 (1.6532)  time: 5.2017  data: 4.9913  max mem: 1964\n",
      "Epoch: [42]  [352/353]  eta: 0:00:00  lr: 0.000500  loss: 1172000128.0000 (821331170.7649)  classification: 1172000128.0000 (821331170.7649)  bbox_regression: 0.9125 (1.5170)  time: 0.2311  data: 0.0793  max mem: 1964\n",
      "Epoch: [42] Total time: 0:02:15 (0.3844 s / it)\n",
      "Epoch: [43]  [  0/353]  eta: 0:29:26  lr: 0.000500  loss: 1124176896.0000 (1124176896.0000)  classification: 1124176896.0000 (1124176896.0000)  bbox_regression: 2.6828 (2.6828)  time: 5.0044  data: 4.8132  max mem: 1964\n",
      "Epoch: [43]  [352/353]  eta: 0:00:00  lr: 0.000500  loss: 250040672.0000 (505463674.2890)  classification: 250040672.0000 (505463674.2890)  bbox_regression: 0.8297 (1.4924)  time: 0.2624  data: 0.1053  max mem: 1964\n",
      "Epoch: [43] Total time: 0:02:12 (0.3744 s / it)\n",
      "Epoch: [44]  [  0/353]  eta: 0:29:46  lr: 0.000500  loss: 238329680.0000 (238329680.0000)  classification: 238329680.0000 (238329680.0000)  bbox_regression: 0.8615 (0.8615)  time: 5.0620  data: 4.8333  max mem: 1964\n",
      "Epoch: [44]  [352/353]  eta: 0:00:00  lr: 0.000500  loss: 96556408.0000 (145104323.0482)  classification: 96556408.0000 (145104323.0028)  bbox_regression: 1.4770 (1.5112)  time: 0.2776  data: 0.1153  max mem: 1964\n",
      "Epoch: [44] Total time: 0:02:13 (0.3783 s / it)\n",
      "Epoch: [45]  [  0/353]  eta: 0:30:43  lr: 0.000500  loss: 74318552.0000 (74318552.0000)  classification: 74318552.0000 (74318552.0000)  bbox_regression: 1.3508 (1.3508)  time: 5.2223  data: 4.9960  max mem: 1964\n",
      "Epoch: [45]  [352/353]  eta: 0:00:00  lr: 0.000500  loss: 488651168.0000 (997103074.4363)  classification: 488651168.0000 (997103074.4023)  bbox_regression: 1.6157 (1.5159)  time: 0.5385  data: 0.2679  max mem: 1964\n",
      "Epoch: [45] Total time: 0:03:13 (0.5471 s / it)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/beomgon/anaconda3/envs/pytorch_retina/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3437, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-22-28b577864034>\", line 26, in <module>\n",
      "    evaluate(model, test_loader, device=device)\n",
      "  File \"/home/beomgon/anaconda3/envs/pytorch_retina/lib/python3.7/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"../engine.py\", line 81, in evaluate\n",
      "    coco = get_coco_api_from_dataset(data_loader.dataset)\n",
      "  File \"../coco_utils.py\", line 206, in get_coco_api_from_dataset\n",
      "    return convert_to_coco_api(dataset)\n",
      "  File \"../coco_utils.py\", line 155, in convert_to_coco_api\n",
      "    img, targets = ds[img_idx]\n",
      "  File \"../dataset.py\", line 83, in __getitem__\n",
      "    image = cv2.imread(self.default_path + path)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/beomgon/anaconda3/envs/pytorch_retina/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/beomgon/anaconda3/envs/pytorch_retina/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/beomgon/anaconda3/envs/pytorch_retina/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/beomgon/anaconda3/envs/pytorch_retina/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/beomgon/anaconda3/envs/pytorch_retina/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/beomgon/anaconda3/envs/pytorch_retina/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/beomgon/anaconda3/envs/pytorch_retina/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/beomgon/anaconda3/envs/pytorch_retina/lib/python3.7/inspect.py\", line 739, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"/home/beomgon/anaconda3/envs/pytorch_retina/lib/python3.7/inspect.py\", line 708, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"/home/beomgon/anaconda3/envs/pytorch_retina/lib/python3.7/inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"/home/beomgon/anaconda3/envs/pytorch_retina/lib/python3.7/genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-28b577864034>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# evaluate after every epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'total time is {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_retina/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch/LBP_scl/faster-rcnn/engine.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, data_loader, device)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mcoco\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_coco_api_from_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m     \u001b[0miou_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_iou_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch/LBP_scl/faster-rcnn/coco_utils.py\u001b[0m in \u001b[0;36mget_coco_api_from_dataset\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoco\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mconvert_to_coco_api\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch/LBP_scl/faster-rcnn/coco_utils.py\u001b[0m in \u001b[0;36mconvert_to_coco_api\u001b[0;34m(ds)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;31m# targets = ds.get_annotations(img_idx)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m         \u001b[0mimage_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"image_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch/LBP_scl/faster-rcnn/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/pytorch_retina/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2060\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2061\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2062\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_retina/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2062\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2063\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0;32m-> 2064\u001b[0;31m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[1;32m   2065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2066\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_retina/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1368\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_retina/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1268\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1269\u001b[0m             )\n\u001b[1;32m   1270\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Minimal'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_retina/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0;32m-> 1125\u001b[0;31m                                                                tb_offset)\n\u001b[0m\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m         \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mColors\u001b[0m  \u001b[0;31m# just a shorthand + quicker name lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_retina/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_retina/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "from train_lbp import train_one_epoch\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(args.epochs):\n",
    "    train_one_epoch(model, optimizer, train_loader, device, epoch, args.print_freq)\n",
    "    lr_scheduler.step()\n",
    "    \n",
    "    if epoch > 60 and epoch % 5 == 0 :\n",
    "        if args.output_dir:\n",
    "            checkpoint = {\n",
    "                'model': model.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'lr_scheduler': lr_scheduler.state_dict(),\n",
    "                'args': args,\n",
    "                'epoch': epoch\n",
    "            }\n",
    "            utils.save_on_master(\n",
    "                checkpoint,\n",
    "                os.path.join(args.output_dir, 'model_{}.pth'.format(epoch)))\n",
    "            utils.save_on_master(\n",
    "                checkpoint,\n",
    "                os.path.join(args.output_dir, 'checkpoint.pth'))\n",
    "\n",
    "    if epoch > 40 and epoch % 5 == 0 :\n",
    "        # evaluate after every epoch\n",
    "        evaluate(model, test_loader, device=device)    \n",
    "print('total time is {}'.format(time.time() - start_time))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acoustic-young",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endless-liabilities",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "images, targets = next(iter(test_loader))\n",
    "images = list(img.to(device) for img in images)\n",
    "with torch.no_grad():\n",
    "    outputs = model(images)\n",
    "    outputs = [{k: v.to(device) for k, v in t.items()} for t in outputs]\n",
    "    \n",
    "images = [image.to('cpu') for image in images]\n",
    "outputs = [{k: v.to('cpu') for k, v in t.items()} for t in outputs]    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "closing-gossip",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identified-cache",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_NUM = 0\n",
    "targets[IMAGE_NUM]['image_id'].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upper-tackle",
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualize import visualize\n",
    "IMAGE_NUM = 2\n",
    "image = images[IMAGE_NUM].numpy()\n",
    "image = np.transpose(image, (1, 2, 0))\n",
    "img_id = targets[IMAGE_NUM]['image_id'].item()\n",
    "img_path = df[df['ID']==img_id].file_name.values[0]\n",
    "print(img_path)\n",
    "ground_boxes = targets[IMAGE_NUM]['boxes']\n",
    "out_boxes = outputs[IMAGE_NUM]['boxes']\n",
    "out_scores = outputs[IMAGE_NUM]['scores']\n",
    "print(out_scores)\n",
    "\n",
    "pred_boxes = []\n",
    "for b, s in zip(out_boxes, out_scores) :\n",
    "    if s > 0.5 :\n",
    "        pred_boxes.append(b.numpy())\n",
    "\n",
    "        \n",
    "import cv2\n",
    "abs_path = '/home/NAS/nas4/project_scl/'\n",
    "image = cv2.imread(abs_path + img_path)\n",
    "visualize(image, ground_boxes, pred_boxes)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "going-identification",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_retina",
   "language": "python",
   "name": "pytorch_retina"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
