{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "timely-clerk",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://herbwood.tistory.com/11?category=867198"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "czech-lobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "from typing import Tuple, List, Dict, Optional\n",
    "from torch import nn, Tensor\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "# from torch.utils.data.sampler import Sampler\n",
    "import torch.optim as optim\n",
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "spare-thriller",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models._utils import IntermediateLayerGetter\n",
    "from torchvision.ops.feature_pyramid_network import FeaturePyramidNetwork, LastLevelMaxPool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "external-operations",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet18 = torchvision.models.resnet18(pretrained=True)\n",
    "resnet18.inplanes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "recovered-hands",
   "metadata": {},
   "outputs": [],
   "source": [
    "body = IntermediateLayerGetter(resnet18, return_layers={'layer1': '0', 'layer2': '1', 'layer3': '2', 'layer4': '3'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "still-photographer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'layer1': '0', 'layer2': '1', 'layer3': '2', 'layer4': '3'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[64, 128, 256, 512]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers_to_train = [\"layer4\", \"layer3\", \"layer2\", \"layer1\", \"conv1\"][:4]\n",
    "returned_layers = [1, 2, 3, 4]\n",
    "return_layers = {f\"layer{k}\": str(v) for v, k in enumerate(returned_layers)}\n",
    "print(return_layers)\n",
    "\n",
    "in_channels_stage2 = resnet18.inplanes // 8\n",
    "in_channels_list = [in_channels_stage2 * 2 ** (i - 1) for i in returned_layers]\n",
    "in_channels_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "perfect-uniform",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(2,3,800,800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "exceptional-utility",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = body(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "copyrighted-coaching",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 512, 25, 25])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['3'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "sharing-trail",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out = resnet18(input)\n",
    "# out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "exterior-chaos",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (resnet18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "portuguese-refund",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from resnet import resnet18\n",
    "# resnet = resnet18()\n",
    "# out = resnet(input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "comparable-addiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_channels = 256\n",
    "fpn = FeaturePyramidNetwork(\n",
    "    in_channels_list=in_channels_list,\n",
    "    out_channels=out_channels,\n",
    "    extra_blocks=LastLevelMaxPool(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "demonstrated-beverage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['0', '1', '2', '3'])\n",
      "odict_keys(['0', '1', '2', '3', 'pool'])\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(2,3,800,800)\n",
    "out = body(input)\n",
    "print(out.keys())\n",
    "feat = fpn(out)\n",
    "print(feat.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "undefined-chance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 256, 13, 13])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat['pool'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "round-destiny",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['0', '1', '2', '3', 'pool'])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "center-figure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeaturePyramidNetwork(\n",
       "  (inner_blocks): ModuleList(\n",
       "    (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (layer_blocks): ModuleList(\n",
       "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (extra_blocks): LastLevelMaxPool()\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "failing-worst",
   "metadata": {},
   "outputs": [],
   "source": [
    "class fpn_network (nn.Module) :\n",
    "    def __init__(self,) :\n",
    "        super(fpn_network, self).__init__()\n",
    "#         super(fpn_network, self).__init__()\n",
    "        self.inner_blocks = nn.ModuleList()\n",
    "        self.layer_blocks = nn.ModuleList()\n",
    "        self.out_channel = 256\n",
    "        \n",
    "        for i in in_channels_list :\n",
    "            inner_block = nn.Conv2d(i, self.out_channel, 1)\n",
    "            layer_block = nn.Conv2d(self.out_channel, self.out_channel, 3, padding=1)\n",
    "            \n",
    "            self.inner_blocks.append(inner_block)\n",
    "            self.layer_blocks.append(layer_block)\n",
    "            \n",
    "        for  m in self.modules() :\n",
    "            if isinstance(m, nn.Conv2d) :\n",
    "                nn.init.kaiming_uniform_(m.weight, a=1)\n",
    "                nn.init.constant_(m.bias, 0)                \n",
    "                \n",
    "    def forward (self, x: Dict[str, Tensor]) -> Dict[str, Tensor]:\n",
    "        names = list(x.keys())\n",
    "        print(names)\n",
    "#         x = list(x.values())  \n",
    "        out = {}\n",
    "#         out.update(x)\n",
    "        \n",
    "        for n in names :\n",
    "#             print(type(n))\n",
    "            li_n = int(n)\n",
    "            print(x[n].shape)\n",
    "            print(self.inner_blocks[li_n])\n",
    "            print(self.layer_blocks[li_n])\n",
    "            out[n] = self.layer_blocks[li_n](self.inner_blocks[li_n](x[n]))\n",
    "        \n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "removable-cannon",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpn = fpn_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "nonprofit-tunnel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input = torch.randn(2,3,800,800)\n",
    "# out = body(input)\n",
    "# print(out.keys())\n",
    "# feat = fpn(out)\n",
    "# print(feat.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "humanitarian-debate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 256, 200, 200])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat['0'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "external-singapore",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.detection.anchor_utils import AnchorGenerator\n",
    "\n",
    "anchor_sizes = ((32,), (64,), (128,), (256,), (512,))\n",
    "aspect_ratios = ((0.5, 1.0, 2.0),) * len(anchor_sizes)\n",
    "rpn_anchor_generator = AnchorGenerator(anchor_sizes, aspect_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "nearby-batman",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-23., -11.,  23.,  11.],\n",
       "         [-16., -16.,  16.,  16.],\n",
       "         [-11., -23.,  11.,  23.]]),\n",
       " tensor([[-45., -23.,  45.,  23.],\n",
       "         [-32., -32.,  32.,  32.],\n",
       "         [-23., -45.,  23.,  45.]]),\n",
       " tensor([[-91., -45.,  91.,  45.],\n",
       "         [-64., -64.,  64.,  64.],\n",
       "         [-45., -91.,  45.,  91.]]),\n",
       " tensor([[-181.,  -91.,  181.,   91.],\n",
       "         [-128., -128.,  128.,  128.],\n",
       "         [ -91., -181.,   91.,  181.]]),\n",
       " tensor([[-362., -181.,  362.,  181.],\n",
       "         [-256., -256.,  256.,  256.],\n",
       "         [-181., -362.,  181.,  362.]])]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rpn_anchor_generator.cell_anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "removable-great",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 3, 3, 3, 3]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rpn_anchor_generator.num_anchors_per_location()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "gorgeous-height",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rpn_anchor_generator.num_anchors_per_location()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "olive-submission",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.detection.rpn import RPNHead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "processed-worse",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_channels = 256\n",
    "rpn_head = RPNHead(out_channels, rpn_anchor_generator.num_anchors_per_location()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "simplified-object",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 256, 50, 50])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat['2'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "essential-meaning",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = list(feat.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "engaging-grenada",
   "metadata": {},
   "outputs": [],
   "source": [
    "objectness, pred_bbox_deltas = rpn_head(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "recreational-directive",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 100, 100])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objectness[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cognitive-application",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 12, 100, 100])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_bbox_deltas[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "roman-heritage",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_retina",
   "language": "python",
   "name": "pytorch_retina"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
