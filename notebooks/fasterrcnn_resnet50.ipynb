{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "recent-phoenix",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "# from torch.utils.data.sampler import Sampler\n",
    "import torch.optim as optim\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from dataset import LbpDataset, train_transforms, val_transforms, test_transforms, collate_fn, get_data\n",
    "from visualize import visualize\n",
    "from model import fasterrcnn_resnet201_fpn, FastRCNNPredictor\n",
    "from engine import evaluate\n",
    "import utils\n",
    "from train_lbp import get_train_test_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "rental-hanging",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.detection.faster_rcnn import fasterrcnn_resnet50_fpn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "833627bf-228c-4845-ae5d-fe4cce3f68bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "anonymous-greeting",
   "metadata": {},
   "outputs": [],
   "source": [
    "import easydict \n",
    "args = easydict.EasyDict({ \"batch_size\": 4, \n",
    "                          \"epochs\": 50, \n",
    "                          \"data\": 0, \n",
    "                          'lr':0.1,\n",
    "                         'momentum':0.9,\n",
    "                         'weight_decay':1e-4,\n",
    "                         'start_epoch':0,\n",
    "                         'gpu':5,\n",
    "                          'workers':4,\n",
    "                         'output_dir' :'../trained_model/fasterrcnn_resnet50_fpn/'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "typical-young",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 4019 train 3014 test 1005\n",
      "3014\n",
      "1005\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../../data/df.csv')\n",
    "df.head()\n",
    "# Data loading code\n",
    "data_dir = '../../data/df.csv'\n",
    "train_list, test_list = get_train_test_list(data_dir)\n",
    "train_dataset = LbpDataset(train_list, transform=train_transforms)\n",
    "test_dataset = LbpDataset(test_list, transform=val_transforms)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "registered-psychiatry",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = torch.utils.data.RandomSampler(train_dataset)\n",
    "test_sampler = torch.utils.data.SequentialSampler(test_dataset)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=args.batch_size,\n",
    "    sampler=train_sampler, num_workers=args.workers,\n",
    "    collate_fn=utils.collate_fn)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=args.batch_size,\n",
    "    sampler=test_sampler, num_workers=args.workers,\n",
    "    collate_fn=utils.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "monthly-blowing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model is loaded to gpu\n"
     ]
    }
   ],
   "source": [
    "num_classes = 2\n",
    "model = fasterrcnn_resnet50_fpn(pretrained=True, min_size=2048, max_size=2048)\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "device = torch.device('cuda')\n",
    "model.to(device)\n",
    "print('model is loaded to gpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "portable-session",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pretrained.state_dict()\n",
    "# for p in model.parameters() :\n",
    "#     if p.requires_grad == True :\n",
    "#         print(p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "latest-effort",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.head.regression_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fitting-seafood",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "# optimizer = torch.optim.Adam(params, lr=0.0001)\n",
    "optimizer = torch.optim.SGD(\n",
    "       params, lr=0.001, momentum=0.9, weight_decay=1e-4)\n",
    "lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[20, 40, 60, 80, 100], \n",
    "                                                    gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "native-ceremony",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0]  [  0/754]  eta: 0:51:07  lr: 0.001000  loss: 1.0728 (1.0728)  loss_classifier: 0.8199 (0.8199)  loss_box_reg: 0.0059 (0.0059)  loss_objectness: 0.2283 (0.2283)  loss_rpn_box_reg: 0.0186 (0.0186)  time: 4.0687  data: 1.9854  max mem: 18498\n",
      "Epoch: [0]  [600/754]  eta: 0:03:05  lr: 0.001000  loss: 0.0771 (0.1084)  loss_classifier: 0.0244 (0.0285)  loss_box_reg: 0.0084 (0.0086)  loss_objectness: 0.0284 (0.0456)  loss_rpn_box_reg: 0.0056 (0.0256)  time: 1.2021  data: 0.0385  max mem: 18498\n",
      "Epoch: [0]  [753/754]  eta: 0:00:01  lr: 0.001000  loss: 0.0961 (0.1078)  loss_classifier: 0.0336 (0.0292)  loss_box_reg: 0.0137 (0.0091)  loss_objectness: 0.0285 (0.0453)  loss_rpn_box_reg: 0.0053 (0.0242)  time: 1.1689  data: 0.0354  max mem: 18498\n",
      "Epoch: [0] Total time: 0:15:05 (1.2005 s / it)\n",
      "Epoch: [1]  [  0/754]  eta: 0:40:16  lr: 0.001000  loss: 0.0771 (0.0771)  loss_classifier: 0.0212 (0.0212)  loss_box_reg: 0.0025 (0.0025)  loss_objectness: 0.0452 (0.0452)  loss_rpn_box_reg: 0.0083 (0.0083)  time: 3.2046  data: 2.0352  max mem: 18498\n",
      "Epoch: [1]  [600/754]  eta: 0:03:05  lr: 0.001000  loss: 0.0748 (0.1057)  loss_classifier: 0.0231 (0.0362)  loss_box_reg: 0.0052 (0.0151)  loss_objectness: 0.0307 (0.0391)  loss_rpn_box_reg: 0.0043 (0.0152)  time: 1.2084  data: 0.0392  max mem: 18498\n",
      "Epoch: [1]  [753/754]  eta: 0:00:01  lr: 0.001000  loss: 0.0846 (0.1067)  loss_classifier: 0.0281 (0.0345)  loss_box_reg: 0.0088 (0.0141)  loss_objectness: 0.0315 (0.0401)  loss_rpn_box_reg: 0.0068 (0.0181)  time: 1.1736  data: 0.0356  max mem: 18498\n",
      "Epoch: [1] Total time: 0:15:07 (1.2032 s / it)\n",
      "Epoch: [2]  [  0/754]  eta: 0:41:41  lr: 0.001000  loss: 0.1142 (0.1142)  loss_classifier: 0.0557 (0.0557)  loss_box_reg: 0.0274 (0.0274)  loss_objectness: 0.0269 (0.0269)  loss_rpn_box_reg: 0.0043 (0.0043)  time: 3.3179  data: 2.1508  max mem: 18498\n"
     ]
    }
   ],
   "source": [
    "from train_lbp import train_one_epoch\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(120):\n",
    "    train_one_epoch(model, optimizer, train_loader, device, epoch, 600)\n",
    "    lr_scheduler.step()\n",
    "    \n",
    "    if epoch > 20 and epoch % 5 == 0 :\n",
    "        if args.output_dir:\n",
    "            checkpoint = {\n",
    "                'model': model.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'lr_scheduler': lr_scheduler.state_dict(),\n",
    "                'args': args,\n",
    "                'epoch': epoch\n",
    "            }\n",
    "            utils.save_on_master(\n",
    "                checkpoint,\n",
    "                os.path.join(args.output_dir, 'model_{}.pth'.format(epoch)))\n",
    "            utils.save_on_master(\n",
    "                checkpoint,\n",
    "                os.path.join(args.output_dir, 'checkpoint.pth'))\n",
    "\n",
    "        # evaluate after every epoch\n",
    "        evaluate(model, test_loader, device=device)    \n",
    "print('total time is {}'.format(time.time() - start_time))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "framed-detail",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model, test_loader, device=device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inappropriate-briefing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
